{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Introduction to Deep Learning & Neural Networks with Keras</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Build a regression model using the Keras library to model data about concrete compressive strength\n",
    " \n",
    "The predictors in the data of concrete strength include:\n",
    "\n",
    "- Cement\n",
    "- Blast Furnace Slag\n",
    "- Fly Ash\n",
    "- Water\n",
    "- Superplasticizer\n",
    "- Coarse Aggregate\n",
    "- Fine Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>PART A - Build a baseline model </b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (1030, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = concrete_data\n",
    "X = X.drop(columns='Strength', axis=1)\n",
    "print(\"X.shape: \", X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape:  (1030,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=concrete_data['Strength']\n",
    "print(\"Y.shape: \", Y.shape)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "- Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = X.shape[1]\n",
    "\n",
    "def get_nn_regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "model = get_nn_regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (721, 8)\n",
      "test_x.shape:  (309, 8)\n",
      "train_y.shape:  (721,)\n",
      "test_y.shape:  (309,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=.30)\n",
    "\n",
    "print(\"train_x.shape: \", train_x.shape)\n",
    "print(\"test_x.shape: \", test_x.shape)\n",
    "print(\"train_y.shape: \", train_y.shape)\n",
    "print(\"test_y.shape: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the model on the training data using 50 epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/50\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 14289.1753 - val_loss: 7911.4465\n",
      "Epoch 2/50\n",
      "504/504 [==============================] - 0s 415us/step - loss: 5410.3388 - val_loss: 3293.0544\n",
      "Epoch 3/50\n",
      "504/504 [==============================] - 0s 319us/step - loss: 3084.8342 - val_loss: 2631.1640\n",
      "Epoch 4/50\n",
      "504/504 [==============================] - 0s 471us/step - loss: 2542.5940 - val_loss: 2089.9603\n",
      "Epoch 5/50\n",
      "504/504 [==============================] - 0s 353us/step - loss: 2015.4417 - val_loss: 1699.5105\n",
      "Epoch 6/50\n",
      "504/504 [==============================] - 0s 418us/step - loss: 1644.2032 - val_loss: 1417.1503\n",
      "Epoch 7/50\n",
      "504/504 [==============================] - 0s 378us/step - loss: 1336.8563 - val_loss: 1179.6257\n",
      "Epoch 8/50\n",
      "504/504 [==============================] - 0s 417us/step - loss: 1098.8520 - val_loss: 987.7656\n",
      "Epoch 9/50\n",
      "504/504 [==============================] - 0s 376us/step - loss: 916.0581 - val_loss: 822.8840\n",
      "Epoch 10/50\n",
      "504/504 [==============================] - 0s 388us/step - loss: 757.1466 - val_loss: 692.9927\n",
      "Epoch 11/50\n",
      "504/504 [==============================] - 0s 348us/step - loss: 638.7378 - val_loss: 583.0609\n",
      "Epoch 12/50\n",
      "504/504 [==============================] - 0s 369us/step - loss: 536.3995 - val_loss: 490.3283\n",
      "Epoch 13/50\n",
      "504/504 [==============================] - 0s 408us/step - loss: 450.8725 - val_loss: 417.3739\n",
      "Epoch 14/50\n",
      "504/504 [==============================] - 0s 360us/step - loss: 383.3225 - val_loss: 357.4184\n",
      "Epoch 15/50\n",
      "504/504 [==============================] - 0s 372us/step - loss: 328.9702 - val_loss: 312.9867\n",
      "Epoch 16/50\n",
      "504/504 [==============================] - 0s 392us/step - loss: 285.4327 - val_loss: 267.6768\n",
      "Epoch 17/50\n",
      "504/504 [==============================] - 0s 401us/step - loss: 250.5775 - val_loss: 236.8843\n",
      "Epoch 18/50\n",
      "504/504 [==============================] - 0s 438us/step - loss: 224.6913 - val_loss: 211.0419\n",
      "Epoch 19/50\n",
      "504/504 [==============================] - 0s 403us/step - loss: 203.0773 - val_loss: 192.9442\n",
      "Epoch 20/50\n",
      "504/504 [==============================] - 0s 357us/step - loss: 186.8017 - val_loss: 174.5059\n",
      "Epoch 21/50\n",
      "504/504 [==============================] - 0s 396us/step - loss: 173.2198 - val_loss: 164.3303\n",
      "Epoch 22/50\n",
      "504/504 [==============================] - 0s 398us/step - loss: 166.8237 - val_loss: 152.3208\n",
      "Epoch 23/50\n",
      "504/504 [==============================] - 0s 380us/step - loss: 155.5947 - val_loss: 145.9899\n",
      "Epoch 24/50\n",
      "504/504 [==============================] - 0s 366us/step - loss: 150.2425 - val_loss: 137.8877\n",
      "Epoch 25/50\n",
      "504/504 [==============================] - 0s 359us/step - loss: 145.9001 - val_loss: 132.9615\n",
      "Epoch 26/50\n",
      "504/504 [==============================] - 0s 295us/step - loss: 140.2867 - val_loss: 129.2298\n",
      "Epoch 27/50\n",
      "504/504 [==============================] - 0s 498us/step - loss: 137.4883 - val_loss: 125.1426\n",
      "Epoch 28/50\n",
      "504/504 [==============================] - 0s 387us/step - loss: 134.6925 - val_loss: 122.8157\n",
      "Epoch 29/50\n",
      "504/504 [==============================] - 0s 378us/step - loss: 132.8062 - val_loss: 121.4098\n",
      "Epoch 30/50\n",
      "504/504 [==============================] - 0s 440us/step - loss: 129.6121 - val_loss: 118.3366\n",
      "Epoch 31/50\n",
      "504/504 [==============================] - 0s 386us/step - loss: 129.4928 - val_loss: 117.4009\n",
      "Epoch 32/50\n",
      "504/504 [==============================] - 0s 400us/step - loss: 127.4732 - val_loss: 119.2622\n",
      "Epoch 33/50\n",
      "504/504 [==============================] - 0s 422us/step - loss: 126.5229 - val_loss: 114.9876\n",
      "Epoch 34/50\n",
      "504/504 [==============================] - 0s 429us/step - loss: 127.7360 - val_loss: 115.6210\n",
      "Epoch 35/50\n",
      "504/504 [==============================] - 0s 340us/step - loss: 123.8428 - val_loss: 113.1123\n",
      "Epoch 36/50\n",
      "504/504 [==============================] - 0s 355us/step - loss: 123.8650 - val_loss: 116.6309\n",
      "Epoch 37/50\n",
      "504/504 [==============================] - 0s 465us/step - loss: 123.2612 - val_loss: 111.9007\n",
      "Epoch 38/50\n",
      "504/504 [==============================] - 0s 518us/step - loss: 123.4567 - val_loss: 116.3383\n",
      "Epoch 39/50\n",
      "504/504 [==============================] - 0s 331us/step - loss: 122.3198 - val_loss: 111.0902\n",
      "Epoch 40/50\n",
      "504/504 [==============================] - 0s 401us/step - loss: 121.6907 - val_loss: 112.8681\n",
      "Epoch 41/50\n",
      "504/504 [==============================] - 0s 445us/step - loss: 122.1041 - val_loss: 111.6045\n",
      "Epoch 42/50\n",
      "504/504 [==============================] - 0s 380us/step - loss: 122.8230 - val_loss: 114.9663\n",
      "Epoch 43/50\n",
      "504/504 [==============================] - 0s 366us/step - loss: 121.5239 - val_loss: 112.1519\n",
      "Epoch 44/50\n",
      "504/504 [==============================] - 0s 378us/step - loss: 122.0893 - val_loss: 110.3034\n",
      "Epoch 45/50\n",
      "504/504 [==============================] - 0s 314us/step - loss: 120.9994 - val_loss: 110.0879\n",
      "Epoch 46/50\n",
      "504/504 [==============================] - 0s 376us/step - loss: 121.8578 - val_loss: 109.8365\n",
      "Epoch 47/50\n",
      "504/504 [==============================] - 0s 338us/step - loss: 121.0026 - val_loss: 110.7578\n",
      "Epoch 48/50\n",
      "504/504 [==============================] - 0s 476us/step - loss: 123.8061 - val_loss: 109.3330\n",
      "Epoch 49/50\n",
      "504/504 [==============================] - 0s 372us/step - loss: 123.2375 - val_loss: 114.7954\n",
      "Epoch 50/50\n",
      "504/504 [==============================] - 0s 430us/step - loss: 118.7959 - val_loss: 108.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f024b2470>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_split=0.3, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error :  190.567049312125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "error_partA = mean_squared_error(test_y, yhat)\n",
    "print('error : ' , error_partA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_errors = []\n",
    "\n",
    "for i in range(50):\n",
    "    model = get_nn_regression_model()\n",
    "    #split data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=.30)\n",
    "    #train model\n",
    "    model.fit(train_x, train_y, validation_split=0.3, epochs=50, verbose=0)\n",
    "    #evaluate model\n",
    "    yhat = model.predict(test_x)\n",
    "    error = mean_squared_error(test_y, yhat)\n",
    "    MSE_errors.append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Errors - mean 546.275818282928\n",
      "MSE Errors - standard deviation 801.1974919336554\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE Errors - mean\" , np.mean(MSE_errors))\n",
    "print(\"MSE Errors - standard deviation\" , np.std(MSE_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>PART B - Normalize the data</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_inputs():\n",
    "    X = concrete_data\n",
    "    X = X.drop(columns='Strength', axis=1)\n",
    "    X = (X - X.mean()) / X.std()  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_inputs() \n",
    "\n",
    "MSE_errors = []\n",
    "\n",
    "for i in range(50):\n",
    "    model = get_nn_regression_model()\n",
    "    #split data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=.30)\n",
    "    #train model\n",
    "    model.fit(train_x, train_y, validation_split=0.3, epochs=50, verbose=0)\n",
    "    #evaluate model\n",
    "    yhat = model.predict(test_x)\n",
    "    error = mean_squared_error(test_y, yhat)\n",
    "    MSE_errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Errors - mean 653.3811739812693\n",
      "MSE Errors - standard deviation 135.34665461975644\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE Errors - mean\" , np.mean(MSE_errors))\n",
    "print(\"MSE Errors - standard deviation\" , np.std(MSE_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compared to A, there is not much diference in the mean of the errors, but the standard deviation is smaller</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>PART C - Increate the number of epochs</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_inputs()\n",
    "\n",
    "MSE_errors_partC = []\n",
    "\n",
    "for i in range(50):\n",
    "    model = get_nn_regression_model()\n",
    "    #split data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=0.30)\n",
    "    #train model\n",
    "    model.fit(train_x, train_y, validation_split=0.3, epochs=100, verbose=0)\n",
    "    #evaluate model\n",
    "    yhat = model.predict(test_x)\n",
    "    error = mean_squared_error(test_y, yhat)\n",
    "    MSE_errors_partC.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Errors - mean 213.66439857456174\n",
      "MSE Errors - standard deviation 29.547836419368103\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE Errors - mean\" , np.mean(MSE_errors_partC))\n",
    "print(\"MSE Errors - standard deviation\" , np.std(MSE_errors_partC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compared to B, both the mean and stanrd deviation of the errors are smaller</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>PART D - Increase the number of hidden layers </b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_nn_regression_model():\n",
    "    model_deep = Sequential()\n",
    "    model_deep.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model_deep.add(Dense(10, activation='relu'))\n",
    "    model_deep.add(Dense(10, activation='relu'))\n",
    "    model_deep.add(Dense(1))\n",
    "\n",
    "    model_deep.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_inputs()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=.30)\n",
    "\n",
    "MSE_errors_partD = []\n",
    "\n",
    "for i in range(50):\n",
    "    model_deep = get_deep_nn_regression_model()\n",
    "    #split data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=.30)\n",
    "    #train model\n",
    "    model_deep.fit(train_x, train_y, validation_split=0.3, epochs=50, verbose=0)\n",
    "    #evaluate model\n",
    "    yhat = model_deep.predict(test_x)\n",
    "    error = mean_squared_error(test_y, yhat)\n",
    "    MSE_errors_partD.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Errors - mean 52.061332353000395\n",
      "MSE Errors - standard deviation 23.454265469783824\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE Errors - mean\" , np.mean(MSE_errors_partD))\n",
    "print(\"MSE Errors - standard deviation\" , np.std(MSE_errors_partD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compared to B, mean and standard deviation of errors are smaller</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compared to C, mean of errors is smaller, and standard deviation is similar</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>\n",
    "A deeper model with normlized data obtains less error than a normalized model with more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PART A</b>\n",
    "- MSE Errors - mean 546.275818282928\n",
    "- MSE Errors - standard deviation 801.1974919336554\n",
    "\n",
    "<b>PART B : Normalized data</b>\n",
    "- MSE Errors - mean 653.3811739812693\n",
    "- MSE Errors - standard deviation 135.34665461975644\n",
    "\n",
    "<b>PART C : Normalized data + more epochs</b>\n",
    "- MSE Errors - mean 213.66439857456174\n",
    "- MSE Errors - standard deviation 29.547836419368103\n",
    "\n",
    "<b>PART D : Normalized data + more hiden layers</b>\n",
    "- MSE Errors - mean 52.061332353000395\n",
    "- MSE Errors - standard deviation 23.454265469783824"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
